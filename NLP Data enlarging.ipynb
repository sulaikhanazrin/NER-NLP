{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c22d2f2-1f69-452c-8313-074d6d234c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  District        PS Name     FIR No Date Report  \\\n",
      "0  THIRUVANANTHAPURAM CITY  Vattiyoorkavu  7000/2019  13/01/2019   \n",
      "1  THIRUVANANTHAPURAM CITY     Vanchiyoor  7001/2019  04/01/2019   \n",
      "2  THIRUVANANTHAPURAM CITY     Vanchiyoor  7002/2019  02/01/2019   \n",
      "3  THIRUVANANTHAPURAM CITY     Vanchiyoor  7003/2019  02/01/2019   \n",
      "4  THIRUVANANTHAPURAM CITY     Vanchiyoor  7004/2019  08/01/2019   \n",
      "\n",
      "  Date Accident Time Report Time Accident     Sections    Accident type  \\\n",
      "0    01/12/2019    18:00:00      17:30:00  279,337,338     Minor Injury   \n",
      "1    31/12/2019    11:25:00      06:30:00          279            Fatal   \n",
      "2    24/12/2019    17:40:00      08:45:00    MO(Minor)  Grevious Injury   \n",
      "3    01/01/2019    16:13:00      14:15:00  279,337,338  Grevious Injury   \n",
      "4    17/01/2019    18:15:00      17:45:00  279,337,338  Grevious Injury   \n",
      "\n",
      "   Death  ...       Collision         Type Road  Road Features  Visibility  \\\n",
      "0      0  ...   Hit from Back  National Highway  Straight Road        Good   \n",
      "1      1  ...  Hit Pedestrian  National Highway  Straight Road        Good   \n",
      "2      0  ...   Hit from Back     State Highway  Straight Road        Good   \n",
      "3      0  ...   Hit from Back        Other Road    Curved Road        Good   \n",
      "4      0  ...   Hit from Side     State Highway  Straight Road        Good   \n",
      "\n",
      "   Traffic Control  Accussed Vehicle Victim Vehicle  FIR      Month-Year  \\\n",
      "0     Uncontrolled            Tipper    Motor Cycle  NaN      March 2021   \n",
      "1     Uncontrolled       Motor Cycle    Motor Cycle  NaN     August 2019   \n",
      "2     Uncontrolled       Motor Cycle        Scooter  NaN   November 2023   \n",
      "3     Uncontrolled     Auto rickshaw    Motor Cycle  NaN        May 2022   \n",
      "4     Uncontrolled       Motor Cycle            Car  NaN  September 2022   \n",
      "\n",
      "                                     Accident_Report  \n",
      "0  On 01/12/2019 at 05:17, a Minor Injury collisi...  \n",
      "1  On 31/12/2019 at 00:40, a Fatal crash occurred...  \n",
      "2  On 24/12/2019 at 12:15, a Grevious Injury cras...  \n",
      "3  On 01/01/2019 at 01:58, a Grevious Injury acci...  \n",
      "4  On 17/01/2019 at 23:21, a Grevious Injury acci...  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Total rows: 50000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# List of file paths (include all months and years)\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\sulai\\Downloads\\NLP\\Police-Traffic.xlsx - dummy JAN 2019.csv\",\n",
    "    r\"C:\\Users\\sulai\\Downloads\\NLP\\Police-Traffic.xlsx - dummy JAN 2020.csv\",\n",
    "    r\"C:\\Users\\sulai\\Downloads\\NLP\\Police-Traffic.xlsx - dummy JAN 2021 final.csv\",\n",
    "    r\"C:\\Users\\sulai\\Downloads\\NLP\\Police-Traffic.xlsx - dummy JAN 2022 final.csv\",\n",
    "    r\"C:\\Users\\sulai\\Downloads\\NLP\\Police-Traffic.xlsx - dummy JAN 2023 final.csv\"\n",
    "]\n",
    "\n",
    "# Read and combine all datasets\n",
    "dfs = [pd.read_csv(file) for file in file_paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Define months and years for dataset balancing\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "years = list(range(2019, 2024))\n",
    "\n",
    "# Function to randomly assign a month and year\n",
    "def assign_month_year():\n",
    "    month = random.choice(months)\n",
    "    year = random.choice(years)\n",
    "    return f\"{month} {year}\"\n",
    "\n",
    "# Apply month-year assignment\n",
    "df[\"Month-Year\"] = [assign_month_year() for _ in range(len(df))]\n",
    "\n",
    "# Ensure each month-year combination is present\n",
    "all_month_years = [f\"{m} {y}\" for y in years for m in months]\n",
    "existing_month_years = df[\"Month-Year\"].unique()\n",
    "missing_month_years = set(all_month_years) - set(existing_month_years)\n",
    "\n",
    "# If any months are missing, create additional data for them\n",
    "if missing_month_years:\n",
    "    extra_rows = df.sample(len(missing_month_years), replace=True).copy()\n",
    "    extra_rows[\"Month-Year\"] = list(missing_month_years)\n",
    "    df = pd.concat([df, extra_rows], ignore_index=True)\n",
    "\n",
    "# Function to generate structured accident reports with enhanced randomization\n",
    "def generate_accident_report(row):\n",
    "    # Randomly tweak time within a 15-minute window\n",
    "    try:\n",
    "        accident_time = datetime.strptime(row['Time Accident'], \"%H:%M\")\n",
    "        accident_time += timedelta(minutes=random.randint(-15, 15))\n",
    "        time_str = accident_time.strftime(\"%H:%M\")\n",
    "    except:\n",
    "        time_str = f\"{random.randint(0, 23):02}:{random.randint(0, 59):02}\"\n",
    "    \n",
    "    # Random variations for better uniqueness\n",
    "    visibility_variants = [\"clear\", \"foggy\", \"hazy\", \"partly cloudy\", \"misty\", \"obscured\"]\n",
    "    weather_variants = [\"sunny\", \"rainy\", \"overcast\", \"stormy\", \"drizzly\", \"windy\"]\n",
    "    road_variants = [\"highway\", \"narrow road\", \"residential street\", \"city road\", \"country lane\", \"urban street\"]\n",
    "    accident_synonyms = [\"accident\", \"collision\", \"crash\", \"incident\", \"mishap\"]\n",
    "    \n",
    "    visibility = random.choice(visibility_variants) if pd.notna(row['Visibility']) else \"unknown visibility\"\n",
    "    weather = random.choice(weather_variants) if pd.notna(row['Weather']) else \"unknown weather\"\n",
    "    road_type = random.choice(road_variants)\n",
    "    accident_term = random.choice(accident_synonyms)\n",
    "    \n",
    "    return (f\"On {row['Date Accident']} at {time_str}, a {row['Accident type']} {accident_term} occurred in {row['District']}, \"\n",
    "            f\"{row['City/Town/ Village']} at {row['Place of Occurance']}. The {accident_term} involved a {row['Accussed Vehicle']} and a {row['Victim Vehicle']}. \"\n",
    "            f\"As a result, {row['Death']} person(s) died, {row['Grievous']} suffered serious injuries, and {row['Minor']} had minor injuries. \"\n",
    "            f\"The weather was {weather} with {visibility} visibility. \"\n",
    "            f\"The {accident_term} took place on a {road_type} with {row['Road Features']} road features and {row['Traffic Control']} traffic control. \"\n",
    "            f\"This incident was recorded in {row['Month-Year']}. \")\n",
    "\n",
    "# Apply function to generate paragraph-like sentences\n",
    "df[\"Accident_Report\"] = df.apply(generate_accident_report, axis=1)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"Accident_Report\"], keep=\"first\")\n",
    "\n",
    "# Ensure dataset has at least 50,000 unique rows\n",
    "while len(df) < 50000:\n",
    "    additional_rows_needed = 50000 - len(df)\n",
    "    extra_samples = df.sample(n=additional_rows_needed, replace=True).copy()\n",
    "    extra_samples[\"Accident_Report\"] = extra_samples[\"Accident_Report\"].apply(lambda x: x.replace(\"accident\", random.choice([\"collision\", \"crash\", \"incident\", \"mishap\"]))\n",
    "                                                                                     .replace(\"visibility\", random.choice([\"clear\", \"hazy\", \"misty\"]))\n",
    "                                                                                     .replace(\"weather\", random.choice([\"sunny\", \"rainy\", \"overcast\"]))\n",
    "                                                                                     .replace(\"road\", random.choice([\"highway\", \"urban street\", \"city road\"])))\n",
    "    df = pd.concat([df, extra_samples], ignore_index=True)\n",
    "    df = df.drop_duplicates(subset=[\"Accident_Report\"], keep=\"first\")\n",
    "\n",
    "# Save final dataset\n",
    "df[[\"Accident_Report\"]].to_csv(\"accident_sentences_50k.csv\", index=False, header=[\"Accident Report\"])\n",
    "\n",
    "# Print sample and count\n",
    "print(df.head())\n",
    "print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c0908e-678e-4cce-acfa-611485ca928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On 01/12/2019 at 05:17, a Minor Injury collisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On 31/12/2019 at 00:40, a Fatal crash occurred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On 24/12/2019 at 12:15, a Grevious Injury cras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On 01/01/2019 at 01:58, a Grevious Injury acci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On 17/01/2019 at 23:21, a Grevious Injury acci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>On 09/01/2020 at 18:04, a Grevious Injury inci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>On 24/01/2022 at 05:01, a Fatal incident occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>On 29/11/2019 at 08:10, a Grevious Injury mish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>On 19/01/2021 at 21:50, a Grevious Injury coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>On 10/01/2019 at 19:01, a Grevious Injury mish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Accident Report\n",
       "0      On 01/12/2019 at 05:17, a Minor Injury collisi...\n",
       "1      On 31/12/2019 at 00:40, a Fatal crash occurred...\n",
       "2      On 24/12/2019 at 12:15, a Grevious Injury cras...\n",
       "3      On 01/01/2019 at 01:58, a Grevious Injury acci...\n",
       "4      On 17/01/2019 at 23:21, a Grevious Injury acci...\n",
       "...                                                  ...\n",
       "49995  On 09/01/2020 at 18:04, a Grevious Injury inci...\n",
       "49996  On 24/01/2022 at 05:01, a Fatal incident occur...\n",
       "49997  On 29/11/2019 at 08:10, a Grevious Injury mish...\n",
       "49998  On 19/01/2021 at 21:50, a Grevious Injury coll...\n",
       "49999  On 10/01/2019 at 19:01, a Grevious Injury mish...\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"accident_sentences_50k.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ec99a7-e4f9-4aa4-acd2-19fb6b99ad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b9749-b9ce-44c2-a607-a66e8148026f",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98316f47-f99b-4d37-8ad5-164851546162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sulai\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\sulai\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sulai\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sulai\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sulai\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sulai\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2962d1-bae0-42ad-a000-781bfe9dd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbeb8ab-9ab5-4496-8699-9a4d98147048",
   "metadata": {},
   "source": [
    "## 1. Lowercasing:\n",
    "Convert all text to lowercase to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e614128-0767-4899-8a22-dd09c44d9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accident Report'] = df['Accident Report'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c64c8-857e-41b3-ad5f-fa5a8f66f445",
   "metadata": {},
   "source": [
    "## 2.Remove Punctuation:\n",
    "Remove punctuation marks from the text, which may not be useful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4b01d6-d01e-4ecb-874e-c90dd786ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accident Report'] = df['Accident Report'].str.replace(r'\\s+',' ',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff1692-3709-4781-9c1b-00d141a28f77",
   "metadata": {},
   "source": [
    "## 3. Remove Stopwords\n",
    "Stopwords are commonly used words that don’t add much meaning to the text, like “the”, “and”, etc. Removing them is common in text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84196474-84a3-4100-983a-0025bb7affbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['Accident Report'] = df['Accident Report'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e09b406-6618-4f70-b5a5-5c27d329e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        01/12/2019 05:17, minor injury collision occur...\n",
       "1        31/12/2019 00:40, fatal crash occurred thiruva...\n",
       "2        24/12/2019 12:15, grevious injury crash occurr...\n",
       "3        01/01/2019 01:58, grevious injury accident occ...\n",
       "4        17/01/2019 23:21, grevious injury accident occ...\n",
       "                               ...                        \n",
       "49995    09/01/2020 18:04, grevious injury incident occ...\n",
       "49996    24/01/2022 05:01, fatal incident occurred koll...\n",
       "49997    29/11/2019 08:10, grevious injury mishap occur...\n",
       "49998    19/01/2021 21:50, grevious injury collision oc...\n",
       "49999    10/01/2019 19:01, grevious injury mishap occur...\n",
       "Name: Accident Report, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4d27d-56ec-4cc5-9038-76275c6f3261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
